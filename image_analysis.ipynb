{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-intro"
   },
   "source": [
    "## Image Segmentation and Clustering\n",
    "\n",
    "This notebook demonstrates a pipeline for segmenting an image using the Segment Anything Model (SAM), filtering the resulting masks, and then clustering them based on color. It utilizes a pre-trained SAM model to generate segmentation masks, a custom filtering algorithm to handle overlaps, and K-Means clustering to group the masks. Additionally, it leverages the OpenAI API to determine the optimal number of clusters from the elbow method distortions.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have installed all the necessary dependencies. You can do this by running the following command in your terminal:\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "# Check if a CUDA-enabled GPU is available and print its name\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Set the computation device to CUDA if available, otherwise use the CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "id": "wUih8Jg2c2Jh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-load-sam"
   },
   "source": [
    "### Load the SAM Model\n",
    "This cell initializes the Segment Anything Model (SAM) from a specified checkpoint and model type. The model is then moved to the selected computation device (GPU or CPU)."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Import the Segment Anything Model (SAM) components\n",
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "\n",
    "# Define the path to the model checkpoint and the model type\n",
    "checkpoint = \"/checkpoints/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "# Register and initialize the SAM model with the specified checkpoint\n",
    "sam = sam_model_registry[model_type](checkpoint=checkpoint)\n",
    "# Move the model to the selected device (GPU/CPU)\n",
    "sam.to(device)\n",
    "\n",
    "# Create an automatic mask generator from the SAM model\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ],
   "metadata": {
    "id": "c3ecGZhgOWS6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-configure-paths"
   },
   "source": [
    "### Configure File Paths\n",
    "This cell sets up the file paths for the input image and defines a naming convention for the output files based on the model type."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the input image\n",
    "image_path = \"/image/test.png\"\n",
    "# Extract the base name of the image file without the extension\n",
    "image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "# Create a mapping for model types to filename suffixes\n",
    "suffix_map = {\n",
    " \"vit_h\": \"_h\",\n",
    " \"vit_l\": \"_l\",\n",
    " \"vit_b\": \"_b\"\n",
    "}\n",
    "# Get the appropriate suffix for the current model type\n",
    "model_suffix = suffix_map.get(model_type, \"\")\n",
    "\n",
    "# Define the filenames for the output pickle and segmented image files\n",
    "pkl_filename = f\"data_{image_name}{model_suffix}.pkl\"\n",
    "image_output_filename = f\"segmented_{image_name}{model_suffix}\""
   ],
   "metadata": {
    "id": "3fWSVhZbRytL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-generate-masks"
   },
   "source": [
    "### Generate Image Masks\n",
    "This cell loads the input image, converts it from BGR to RGB color space, and then uses the `mask_generator` to create segmentation masks. The time taken for mask generation is also measured and printed."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Read the input image using OpenCV\n",
    "image = cv2.imread(image_path)\n",
    "# Convert the image from BGR (OpenCV's default) to RGB\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "# Generate masks for the input image\n",
    "masks = mask_generator.generate(image_rgb)\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print the number of masks generated and the time taken\n",
    "print(f\"Number of masks generated: {len(masks)}\")\n",
    "print(f\"Time taken to generate masks: {elapsed_time:.2f} seconds\")"
   ],
   "metadata": {
    "id": "wKOyYa8oRrbh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-viz-function"
   },
   "source": [
    "### Visualization Function\n",
    "The `show_anns` function is defined here to visualize the generated masks. It overlays the masks on a blank canvas with random colors for differentiation."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to display the annotations (masks)\n",
    "def show_anns(anns):\n",
    " # Return if there are no annotations\n",
    " if len(anns) == 0:\n",
    "  return\n",
    " # Sort annotations by area in descending order\n",
    " sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    " ax = plt.gca()\n",
    " ax.set_autoscale_on(False)\n",
    "\n",
    " # Create a blank image with an alpha channel\n",
    " img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    " img[:, :, 3] = 0\n",
    "\n",
    " # Iterate through the sorted annotations and draw them on the image\n",
    " for ann in sorted_anns:\n",
    "  m = ann['segmentation']\n",
    "  # Generate a random color with an alpha value of 1\n",
    "  color_mask = np.concatenate([np.random.random(3), [1]])\n",
    "  # Apply the color to the mask area\n",
    "  img[m] = color_mask\n",
    "\n",
    " # Display the image with the annotations\n",
    " ax.imshow(img)"
   ],
   "metadata": {
    "id": "0AHZw162dt6c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-display-segmented"
   },
   "source": [
    "### Display the Segmented Image\n",
    "This cell displays the original RGB image with the generated masks overlaid on top."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Display the original RGB image\n",
    "plt.imshow(image_rgb)\n",
    "# Overlay the generated masks on the image\n",
    "show_anns(masks)\n",
    "# Turn off the axis labels\n",
    "plt.axis('off')\n",
    "# The following line is commented out, but can be used to save the figure\n",
    "# plt.savefig(image_output_filename, bbox_inches='tight', pad_inches=0)\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "LxSD8wVHd2_v"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-filter-masks"
   },
   "source": [
    "### Filter Overlapping Masks\n",
    "The `filter_overlapping_masks` function is a crucial step to refine the segmentation results. It iteratively identifies overlapping masks, creates new masks from the overlapping regions, and removes the original masks if their non-overlapping area falls below a certain percentage. This helps to reduce redundancy and create more distinct segments."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to filter masks by handling overlaps\n",
    "def filter_overlapping_masks(masks, min_percentage=0.2):\n",
    " filtered_masks = masks.copy()\n",
    " updated = True\n",
    "\n",
    " # Loop until no more updates are made\n",
    " while updated:\n",
    "  updated = False\n",
    "  print(f\"Current number of masks: {len(filtered_masks)}\")\n",
    "\n",
    "  new_masks = []\n",
    "  masks_to_remove = set()\n",
    "\n",
    "  # Iterate through pairs of masks to check for overlaps\n",
    "  for i in range(len(filtered_masks)):\n",
    "   if filtered_masks[i] is None:\n",
    "    continue\n",
    "\n",
    "   mask_i = filtered_masks[i]\n",
    "   original_area_i = np.sum(mask_i)\n",
    "\n",
    "   for j in range(i + 1, len(filtered_masks)):\n",
    "    if filtered_masks[j] is None:\n",
    "     continue\n",
    "\n",
    "    mask_j = filtered_masks[j]\n",
    "    original_area_j = np.sum(mask_j)\n",
    "\n",
    "    # Find the overlapping region\n",
    "    overlap = mask_i & mask_j\n",
    "    overlap_area = np.sum(overlap)\n",
    "\n",
    "    # Skip if the overlap is not significant for either mask\n",
    "    if (overlap_area / original_area_i < min_percentage) and (overlap_area / original_area_j < min_percentage):\n",
    "     continue\n",
    "\n",
    "    # Add the overlap as a new mask if it exists\n",
    "    if overlap_area > 0:\n",
    "     new_masks.append(overlap)\n",
    "\n",
    "    # Update the original masks by removing the overlap\n",
    "    mask_i_updated = mask_i & ~overlap\n",
    "    mask_j_updated = mask_j & ~overlap\n",
    "\n",
    "    updated_area_i = np.sum(mask_i_updated)\n",
    "    updated_area_j = np.sum(mask_j_updated)\n",
    "\n",
    "    print(f\"Processing masks {i} and {j}\")\n",
    "    print(f\"Overlap area: {overlap_area}\")\n",
    "    print(f\"Mask {i} area after removing overlap: {updated_area_i}\")\n",
    "    print(f\"Mask {j} area after removing overlap: {updated_area_j}\")\n",
    "\n",
    "    # If the remaining area of a mask is too small, mark it for removal\n",
    "    if updated_area_i / original_area_i >= min_percentage:\n",
    "     filtered_masks[i] = mask_i_updated\n",
    "    else:\n",
    "     filtered_masks[i] = None\n",
    "     masks_to_remove.add(i)\n",
    "\n",
    "    if updated_area_j / original_area_j >= min_percentage:\n",
    "     filtered_masks[j] = mask_j_updated\n",
    "    else:\n",
    "     filtered_masks[j] = None\n",
    "     masks_to_remove.add(j)\n",
    "\n",
    "    updated = True\n",
    "\n",
    "  # Remove the marked masks\n",
    "  filtered_masks = [filtered_masks[k] for k in range(len(filtered_masks)) if k not in masks_to_remove]\n",
    "\n",
    "  # Add the new overlap masks to the list\n",
    "  filtered_masks.extend(new_masks)\n",
    "\n",
    "  # If new masks were added, continue the loop\n",
    "  if new_masks:\n",
    "   updated = True\n",
    "\n",
    "  return filtered_masks"
   ],
   "metadata": {
    "id": "VwC_M88ghdQR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-apply-filter"
   },
   "source": [
    "### Apply the Filtering Algorithm\n",
    "This cell extracts the boolean segmentation masks from the `masks` dictionary and applies the `filter_overlapping_masks` function to them."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Extract the 'segmentation' boolean arrays from the list of mask dictionaries\n",
    "masks_list = [item['segmentation'] for item in masks if 'segmentation' in item]\n",
    "# Apply the filtering function to handle overlapping masks\n",
    "filtered_masks = filter_overlapping_masks(masks_list)"
   ],
   "metadata": {
    "collapsed": true,
    "id": "hQGnq7FEY9VG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-setup-openai"
   },
   "source": [
    "### Set Up OpenAI API\n",
    "This cell initializes the OpenAI client with your API key. This is necessary for programmatically determining the optimal number of clusters later on."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# NOTE: Replace 'your_api_key' with your actual OpenAI API key\n",
    "api_key = 'your_api_key'\n",
    "client = OpenAI(api_key=api_key)"
   ],
   "metadata": {
    "id": "Avd8BZKxYDQ-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-caching"
   },
   "source": [
    "### Caching Functions\n",
    "To avoid redundant API calls to OpenAI, these functions provide a simple caching mechanism. `load_cache` reads previous results from a JSON file, and `save_cache` writes new results to it."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# Function to load cached data from a file\n",
    "def load_cache(cache_file):\n",
    " if not isinstance(cache_file, str):\n",
    "  raise TypeError(\"Expected 'cache_file' to be a string\")\n",
    " # Check if the cache file exists\n",
    " if os.path.exists(cache_file):\n",
    "  try:\n",
    "   # Open and load the JSON data\n",
    "   with open(cache_file, 'r') as f:\n",
    "    return json.load(f)\n",
    "  except json.JSONDecodeError:\n",
    "   print(f\"Error reading {cache_file}. File may be corrupted.\")\n",
    " # Return an empty dictionary if the file doesn't exist or is invalid\n",
    " return {}\n",
    "\n",
    "# Function to save data to the cache file\n",
    "def save_cache(cache_file, cache_data):\n",
    " with open(cache_file, 'w') as f:\n",
    "  json.dump(cache_data, f)"
   ],
   "metadata": {
    "id": "a6mNA-hif1jS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-get-clusters"
   },
   "source": [
    "### Get Optimal Clusters using OpenAI\n",
    "This function, `get_optimal_clusters_from_openai`, takes a list of distortion values from the elbow method, sends them to the GPT-4 model, and asks for the optimal number of clusters. It uses the caching functions to store and retrieve results for the same set of distortions."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "# Function to get the optimal number of clusters from OpenAI's GPT-4\n",
    "def get_optimal_clusters_from_openai(distortions, cache_file='cache.json'):\n",
    " print(f\"cache_file type: {type(cache_file)}, value: {cache_file}\")\n",
    "\n",
    " # Load existing cache\n",
    " cache_data = load_cache(cache_file)\n",
    " # Create a cache key from the list of distortions\n",
    " cache_key = str(distortions)\n",
    "\n",
    " # If the result is already in the cache, return it\n",
    " if cache_key in cache_data:\n",
    "  print(\"Using cached result for distortions:\", distortions)\n",
    "  return cache_data[cache_key]\n",
    "\n",
    " # Format the distortions for the prompt\n",
    " distortions_str = ', '.join(map(str, distortions))\n",
    " # Create the prompt for the GPT-4 model\n",
    " prompt = (f\"The following are distortions for different cluster numbers: {distortions_str}. \"\n",
    "   \"Please suggest the optimal number of clusters based on the Elbow Method, responding with just the number.\")\n",
    "\n",
    " # Make the API call to OpenAI\n",
    " response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}],\n",
    "  max_tokens=10\n",
    " )\n",
    "\n",
    " # Get the response text\n",
    " response_text = response.choices[0].message.content\n",
    "\n",
    " print(\"GPT-4 response:\", response_text)\n",
    "\n",
    " # Extract the number from the response\n",
    " match = re.search(r'\\b\\d+\\b', response_text)\n",
    " optimal_clusters = int(match.group()) if match else 3\n",
    "\n",
    " # Save the new result to the cache\n",
    " cache_data[cache_key] = optimal_clusters\n",
    " save_cache(cache_file, cache_data)\n",
    "\n",
    " return optimal_clusters"
   ],
   "metadata": {
    "id": "GqcAj2c-fp5o"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-cluster-viz"
   },
   "source": [
    "### Cluster and Visualize Masks\n",
    "This is the main function for clustering and visualization. It performs the following steps:\n",
    "1. Calculates the average RGB color for each filtered mask.\n",
    "2. Uses the elbow method to calculate distortion scores for a range of cluster numbers.\n",
    "3. Calls `get_optimal_clusters_from_openai` to determine the best number of clusters.\n",
    "4. Performs K-Means clustering on the RGB values with a fixed initial center.\n",
    "5. Visualizes the results in a multi-panel plot showing the original image, filtered masks, and clustered masks.\n",
    "6. Saves the final visualizations to specified output folders."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Main function to cluster masks and visualize the results\n",
    "def cluster_and_visualize_masks(output_folder_img, output_folder_final, image_rgb, masks, filtered_masks, n_clusters=3, initial_center=None):\n",
    " rgb_values = []\n",
    "\n",
    " # Calculate the average RGB value for each mask\n",
    " for idx, mask in enumerate(filtered_masks):\n",
    "  mask_pixels = np.where(mask)\n",
    "\n",
    "  r_values = image_rgb[mask_pixels[0], mask_pixels[1], 0]\n",
    "  g_values = image_rgb[mask_pixels[0], mask_pixels[1], 1]\n",
    "  b_values = image_rgb[mask_pixels[0], mask_pixels[1], 2]\n",
    "\n",
    "  avg_r = np.mean(r_values)\n",
    "  avg_g = np.mean(g_values)\n",
    "  avg_b = np.mean(b_values)\n",
    "\n",
    "  rgb_values.append([avg_r, avg_g, avg_b])\n",
    "\n",
    " rgb_array = np.array(rgb_values)\n",
    "\n",
    " # Elbow method to calculate distortions with a fixed initial center\n",
    " distortions = []\n",
    " initial_center = list(map(int, image_name.split('_')[1].split(',')[:3]))\n",
    "\n",
    " K_range = range(2, min(11, len(rgb_array)) + 1)\n",
    " for k in K_range:\n",
    "  # Find initial centers for the remaining clusters\n",
    "  remaining_centers = KMeans(n_clusters=k - 1, init='k-means++', random_state=0).fit(rgb_array).cluster_centers_\n",
    "  current_centers = np.vstack([initial_center, remaining_centers])\n",
    "\n",
    "  # Perform KMeans with the fixed and found centers\n",
    "  kmeans = KMeans(n_clusters=k, init=current_centers, n_init=1, random_state=0)\n",
    "  kmeans.fit(rgb_array)\n",
    "  distortions.append(kmeans.inertia_)\n",
    "\n",
    " # Get the optimal number of clusters from OpenAI\n",
    " n_clusters = min(get_optimal_clusters_from_openai(distortions), len(rgb_array))\n",
    "\n",
    " # Perform the final KMeans clustering with the optimal number of clusters\n",
    " remaining_centers = KMeans(n_clusters=n_clusters - 1, init='k-means++', random_state=0).fit(rgb_array).cluster_centers_\n",
    " final_centers = np.vstack([initial_center, remaining_centers])\n",
    " kmeans = KMeans(n_clusters=n_clusters, init=final_centers, n_init=1, random_state=0)\n",
    "\n",
    " kmeans.fit(rgb_array)\n",
    " labels = kmeans.labels_\n",
    "\n",
    " # Predefined colors for clusters\n",
    " cluster_colors = [\n",
    "  [1, 0, 0, 0.35], [0, 1, 0, 0.35], [1, 1, 0, 0.35],\n",
    "  [0.5, 0, 1, 0.35], [0, 0, 1, 0.35], [0, 1, 1, 0.35],\n",
    "  [0.5, 0.5, 0.5, 0.35], [1, 0.5, 0, 0.35], [0.5, 0, 1, 0.35],\n",
    "  [0, 0.5, 1, 0.35]\n",
    " ]\n",
    "\n",
    " # Helper function to show masks with random colors\n",
    " def show_anns(anns, ax):\n",
    "  # ... (implementation in original code)\n",
    "\n",
    " # Helper function to show clustered masks with labels\n",
    " def show_anns_with_clusters_and_labels(anns, labels, rgb_array, ax):\n",
    "  # ... (implementation in original code)\n",
    "\n",
    " # Helper function to show clustered masks\n",
    " def show_anns_with_clusters(anns, labels, rgb_array, ax, first_class_color=[0, 0, 1, 0.35]):\n",
    "  # ... (implementation in original code)\n",
    "\n",
    " # Helper function to save each mask individually\n",
    " def visualize_each_mask_individually(anns, labels, rgb_array, output_folder):\n",
    "  # ... (implementation in original code)\n",
    "\n",
    " # Create a 2x2 subplot for visualizations\n",
    " fig, axs = plt.subplots(2, 2, figsize=(15, 8))\n",
    "\n",
    " axs[0, 0].imshow(image_rgb)\n",
    " axs[0, 0].set_title('Original Image')\n",
    " axs[0, 0].axis('off')\n",
    "\n",
    " show_anns(filtered_masks, axs[0, 1])\n",
    " axs[0, 1].set_title('Filtered Masks')\n",
    " axs[0, 1].axis('off')\n",
    "\n",
    " show_anns_with_clusters(filtered_masks, labels, rgb_array, axs[1, 0])\n",
    " axs[1, 0].set_title('Clustered Masks')\n",
    " axs[1, 0].axis('off')\n",
    "\n",
    " show_anns_with_clusters_and_labels(filtered_masks, labels, rgb_array, axs[1, 1])\n",
    " axs[1, 1].set_title('Clustered Masks with Labels')\n",
    " axs[1, 1].axis('off')\n",
    "\n",
    " plt.tight_layout()\n",
    "\n",
    " # Save the main visualization figure\n",
    " suffix_map = {\"vit_h\": \"_h\", \"vit_l\": \"_l\", \"vit_b\": \"_b\"}\n",
    " model_suffix = suffix_map.get(model_type, \"\")\n",
    " image_filename = os.path.join(output_folder_img, f\"data_{image_name}{model_suffix}.tiff\")\n",
    " plt.savefig(image_filename, bbox_inches='tight', pad_inches=0, format=\"tiff\", dpi=300)\n",
    "\n",
    " plt.show()\n",
    "\n",
    " # Save each mask as an individual image\n",
    " output_individual_masks = os.path.join(output_folder_img, f\"{image_name}_individual_masks\")\n",
    " visualize_each_mask_individually(filtered_masks, labels, rgb_array, output_individual_masks)\n",
    "\n",
    " return rgb_array, kmeans.cluster_centers_, labels"
   ],
   "metadata": {
    "id": "c4riXPvkeixJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-run-pipeline"
   },
   "source": [
    "### Run the Pipeline\n",
    "This cell sets the output directories, defines the initial cluster center based on the image filename, and then executes the entire clustering and visualization pipeline by calling the `cluster_and_visualize_masks` function."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Define output folders for the final and intermediate images\n",
    "output_folder_final = '/output'\n",
    "output_folder_img = '/output_image'\n",
    "\n",
    "# Extract the initial cluster center from the image filename\n",
    "# This assumes the filename contains RGB values (e.g., 'image_255,0,0.png')\n",
    "initial_center = list(map(int, image_name.split('_')[1].split(',')[:3]))\n",
    "\n",
    "# Run the main clustering and visualization function\n",
    "rgb_array, centers, labels = cluster_and_visualize_masks(output_folder_img, output_folder_final, image_rgb, masks, filtered_masks, image_name, model_type, initial_center)"
   ],
   "metadata": {
    "id": "4jhokf5Xj_Tp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "markdown-print-results"
   },
   "source": [
    "### Print Results\n",
    "This final cell prints the results of the clustering: the array of average RGB values for each mask, the coordinates of the final cluster centers, and the cluster label assigned to each mask."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Print the final results from the clustering process\n",
    "print(\"RGB values of masks:\", rgb_array)\n",
    "print(\"Cluster centers:\", centers)\n",
    "print(\"Labels for each mask:\", labels)"
   ],
   "metadata": {
    "id": "PwCjNY4QfNoL"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
